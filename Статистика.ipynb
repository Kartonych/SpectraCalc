{
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "",
  "signature": "sha256:4ff47227133ca243dce9750f8d925385d74cdbb42c66821ed13b61aff5bef816"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy \n",
      "from sklearn import preprocessing\n",
      "\n",
      "LeftBorder = 672\n",
      "RightBorder = 720\n",
      "\n",
      "path = \"Program\"\n",
      "path_konets = \"Results\"\n",
      "\n",
      "path = os.path.abspath(path)\n",
      "path_konets = os.path.abspath(path_konets)\n",
      "\n",
      "a = os.listdir(path)\n",
      "#a=ListOfFiles\n",
      "\n",
      "time = []\n",
      "for i in a:\n",
      "    string = i.split('_')\n",
      "    num = string[2].split('m')\n",
      "    time.append(int(num[0]))\n",
      "\n",
      "def normalizing(df, df_len):\n",
      "    for i in df_len:\n",
      "        for j in df[i].columns:\n",
      "            if j != 'number':\n",
      "                print(j)\n",
      "                min_max_scaler = preprocessing.MinMaxScaler()\n",
      "                np_scaled = min_max_scaler.fit_transform(df[i][j])\n",
      "                df_normalized = pd.DataFrame(np_scaled)\n",
      "                for jopa in xrange(len(df[i])):\n",
      "                    df[i][j].iloc[jopa] = df_normalized[0].iloc[jopa]\n",
      "            #print(df_normalized[0])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 206,
       "text": [
        "['oreas991_900V_420ms_d2000ns_g5000ns_532nm_24p5J(83mJ)_10Hz_06120_6mm_30mkm_chamber4mm_p2_24.out',\n",
        " 'oreas991_900V_420ms_d2000ns_g5000ns_532nm_24p5J(83mJ)_10Hz_06120_6mm_30mkm_chamber4mm_p1_24.out']"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "            \n",
      "for name in a:\n",
      "    f = open(path + \"/\" + name, \"r+\")    \n",
      "    length = len(f.readline().split())\n",
      "    f.seek(0)\n",
      "    info = f.read()\n",
      "    f.close()\n",
      "    f = open(path + \"/\" + name + \"_1\", \"a\")\n",
      "    f.seek(0)\n",
      "    f.write(\"number\")\n",
      "    for i in xrange(length-1):\n",
      "        f.write(\",spectra\"+str(i+1))\n",
      "    f.write(\"\\n\")\n",
      "    f.write(info)\n",
      "    f.close\n",
      "    f = open(path + \"/\" + name + \"_1\", \"r+\") \n",
      "    txt = f.read().replace('\\t', ',')\n",
      "    f.seek(0)\n",
      "    f.truncate()\n",
      "    f.write(txt)\n",
      "    \n",
      "    #print(f.readline().split())\n",
      "    f.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = []\n",
      "for name in a:\n",
      "    print(name)\n",
      "    g = pd.read_csv(path + \"/\" + name + \"_1\",  dtype=np.float64)\n",
      "    df.append(g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "oreas991_900V_420ms_d2000ns_g5000ns_532nm_24p5J(83mJ)_10Hz_06120_6mm_30mkm_chamber4mm_p2_24.out\n",
        "oreas991_900V_420ms_d2000ns_g5000ns_532nm_24p5J(83mJ)_10Hz_06120_6mm_30mkm_chamber4mm_p1_24.out\n"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for i in xrange(len(df)):\n",
      "#    df[i].index = [str(i) for i in xrange(1, len(df[i]))]\n",
      "\n",
      "#df[1]\n"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u0412\u044b\u0440\u0435\u0437\u0430\u0435\u043c \u043d\u0443\u0436\u043d\u044b\u0439 \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d\n",
      "\n",
      "df_len = xrange(len(df))\n",
      "Length = len(df[0])\n",
      "\n",
      "for i in df_len:\n",
      "    df[i].drop(range(0, LeftBorder, 1), axis=0, inplace = True)\n",
      "    df[i].drop(range(RightBorder, Length, 1), axis=0, inplace = True)\n",
      "\n",
      "#df[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u041d\u0430\u0445\u043e\u0434\u0438\u043c \u0441\u0440\u0435\u0434\u043d\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u043d\u0435\u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u043f\u0438\u043a\u043e\u0432\n",
      "\n",
      "df_len = xrange(len(df))\n",
      "\n",
      "df_mean_no_normal = []\n",
      "\n",
      "for i in df_len:\n",
      "    del df[i]['number']\n",
      "\n",
      "for i in df_len:\n",
      "    print(i)\n",
      "    df_mean_no_normal.append(pd.DataFrame({'mean' : []}))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1\n"
       ]
      }
     ],
     "prompt_number": 211
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u041d\u0430\u0439\u0434\u0435\u043c \u0441\u0440\u0435\u0434\u043d\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\n",
      "\n",
      "for i in df_len:\n",
      "    #for j in xrange(len(df[i]['spectra1'])):\n",
      "    df_mean_no_normal[i]['mean'] = df[i].mean(axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_mean_no_normal[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>mean</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>672</th>\n",
        "      <td>2356341.20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>673</th>\n",
        "      <td>2306019.84</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>674</th>\n",
        "      <td>2272266.72</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>675</th>\n",
        "      <td>2226000.72</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>676</th>\n",
        "      <td>2174078.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>677</th>\n",
        "      <td>2182139.72</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>678</th>\n",
        "      <td>2150364.44</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>679</th>\n",
        "      <td>2148037.92</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>680</th>\n",
        "      <td>2153061.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>681</th>\n",
        "      <td>2160094.32</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>682</th>\n",
        "      <td>2207666.56</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>683</th>\n",
        "      <td>2237325.44</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>684</th>\n",
        "      <td>2275699.60</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>685</th>\n",
        "      <td>2318969.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>686</th>\n",
        "      <td>2346131.12</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>687</th>\n",
        "      <td>2384329.44</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>688</th>\n",
        "      <td>2407726.48</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>689</th>\n",
        "      <td>2420423.28</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>690</th>\n",
        "      <td>2404563.16</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>691</th>\n",
        "      <td>2377617.12</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>692</th>\n",
        "      <td>2353429.80</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>693</th>\n",
        "      <td>2314656.36</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>694</th>\n",
        "      <td>2277743.44</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>695</th>\n",
        "      <td>2268023.12</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>696</th>\n",
        "      <td>2272835.52</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>697</th>\n",
        "      <td>2256277.64</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>698</th>\n",
        "      <td>2257976.36</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>699</th>\n",
        "      <td>2269964.68</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>700</th>\n",
        "      <td>2273249.40</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>701</th>\n",
        "      <td>2287761.68</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>702</th>\n",
        "      <td>2307746.28</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>703</th>\n",
        "      <td>2318303.92</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>704</th>\n",
        "      <td>2413184.56</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>705</th>\n",
        "      <td>2446453.36</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>706</th>\n",
        "      <td>2475795.08</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>707</th>\n",
        "      <td>2518789.20</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>708</th>\n",
        "      <td>2612208.04</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>709</th>\n",
        "      <td>2709036.24</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>710</th>\n",
        "      <td>2866157.68</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>711</th>\n",
        "      <td>3092179.40</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>712</th>\n",
        "      <td>3360152.68</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>713</th>\n",
        "      <td>3711125.32</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>714</th>\n",
        "      <td>4221374.72</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>715</th>\n",
        "      <td>5025215.60</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>716</th>\n",
        "      <td>6173838.60</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>717</th>\n",
        "      <td>7730891.40</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>718</th>\n",
        "      <td>9207409.84</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>719</th>\n",
        "      <td>10089473.00</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 213,
       "text": [
        "            mean\n",
        "672   2356341.20\n",
        "673   2306019.84\n",
        "674   2272266.72\n",
        "675   2226000.72\n",
        "676   2174078.00\n",
        "677   2182139.72\n",
        "678   2150364.44\n",
        "679   2148037.92\n",
        "680   2153061.00\n",
        "681   2160094.32\n",
        "682   2207666.56\n",
        "683   2237325.44\n",
        "684   2275699.60\n",
        "685   2318969.80\n",
        "686   2346131.12\n",
        "687   2384329.44\n",
        "688   2407726.48\n",
        "689   2420423.28\n",
        "690   2404563.16\n",
        "691   2377617.12\n",
        "692   2353429.80\n",
        "693   2314656.36\n",
        "694   2277743.44\n",
        "695   2268023.12\n",
        "696   2272835.52\n",
        "697   2256277.64\n",
        "698   2257976.36\n",
        "699   2269964.68\n",
        "700   2273249.40\n",
        "701   2287761.68\n",
        "702   2307746.28\n",
        "703   2318303.92\n",
        "704   2413184.56\n",
        "705   2446453.36\n",
        "706   2475795.08\n",
        "707   2518789.20\n",
        "708   2612208.04\n",
        "709   2709036.24\n",
        "710   2866157.68\n",
        "711   3092179.40\n",
        "712   3360152.68\n",
        "713   3711125.32\n",
        "714   4221374.72\n",
        "715   5025215.60\n",
        "716   6173838.60\n",
        "717   7730891.40\n",
        "718   9207409.84\n",
        "719  10089473.00"
       ]
      }
     ],
     "prompt_number": 213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def FindInd(a, value, bond):\n",
      "    for i in xrange(len(a)):\n",
      "        bond = bond+1\n",
      "        if a.iloc[i] == value:\n",
      "            return bond"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\u0414\u0435\u043b\u0430\u0435\u043c \u0431\u0430\u0437\u043e\u0432\u0443\u044e \u043b\u0438\u043d\u0438\u044e \u0433\u043e\u0440\u0438\u0437\u043e\u043d\u0442\u0430\u043b\u044c\u043d\u043e\u0439\n",
      "\n",
      "#\u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u0435 \u043c\u0438\u043d\u0438\u043c\u0443\u043c\u043e\u0432 \u0441\u043f\u0440\u0430\u0432\u0430 \u0438 \u0441\u043b\u0435\u0432\u0430, \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u0435 \u0443\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u044f\u043c\u043e\u0439, \u0441\u043e\u0435\u0434\u0438\u043d\u044f\u044e\u0449\u0435\u0439 \u044d\u0442\u0438 \u043c\u0438\u043d\u0438\u043c\u0443\u043c\u044b \u0438 \u0432\u044b\u0447\u0438\u0442\u0430\u043d\u0438\u0435 \u044d\u0442\u043e\u0439 \u043f\u0440\u044f\u043c\u043e\u0439 \u0438\u0437 \u0441\u043f\u0435\u043a\u0442\u0440\u0430"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_len = xrange(len(df))\n",
      "\n",
      "Left_Loc = []\n",
      "Right_Loc = []\n",
      "    \n",
      "Min_of_Left_Loc = pd.DataFrame({'min' : [], 'point' : []}, dtype=float)\n",
      "Min_of_Right_Loc = pd.DataFrame({'min' : [], 'point' : []}, dtype=float)\n",
      "\n",
      "DiameterOfLocality = 15\n",
      "\n",
      "LeftLocal = LeftBorder + DiameterOfLocality\n",
      "RightLocal = RightBorder - DiameterOfLocality\n",
      "\n",
      "def FindPoints(df_mean_no_normal):\n",
      "\n",
      "\n",
      "\n",
      "    #for i in df_len:\n",
      "     #   Left_Loc.append(df_mean_no_normal[i][LeftBorder:LeftLocal])\n",
      "      #  Right_Loc.append(pd.DataFrame(df_mean_no_normal[i].iloc[RightLocal:RightBorder]))\n",
      "        \n",
      "    for i in df_len:\n",
      "        Min_of_Left_Loc['min'].loc[i] = df_mean_no_normal[i]['mean'].loc[LeftBorder:LeftLocal].min()\n",
      "        Min_of_Left_Loc['point'].loc[i] = FindInd(df_mean_no_normal[i]['mean'].loc[LeftBorder:LeftLocal],   Min_of_Left_Loc['min'].loc[i], LeftBorder)\n",
      "        Min_of_Right_Loc['min'].loc[i] = df_mean_no_normal[i]['mean'].loc[RightLocal:RightBorder].min()\n",
      "        Min_of_Right_Loc['point'].loc[i] = FindInd(df_mean_no_normal[i]['mean'].loc[RightLocal:RightBorder],  Min_of_Right_Loc['min'].loc[i], RightLocal)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in df_len:\n",
      "    for j in range(LeftBorder, RightBorder, 1):\n",
      "        df_mean_no_normal[i]['mean'].loc[j] = df_mean_no_normal[i]['mean'].loc[j]/((time[i]+80)/100)\n",
      "\n",
      "\n",
      "FindPoints(df_mean_no_normal)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_mean_no_normal[0]['mean']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 218,
       "text": [
        "672     471268.240\n",
        "673     461203.968\n",
        "674     454453.344\n",
        "675     445200.144\n",
        "676     434815.600\n",
        "677     436427.944\n",
        "678     430072.888\n",
        "679     429607.584\n",
        "680     430612.200\n",
        "681     432018.864\n",
        "682     441533.312\n",
        "683     447465.088\n",
        "684     455139.920\n",
        "685     463793.960\n",
        "686     469226.224\n",
        "687     476865.888\n",
        "688     481545.296\n",
        "689     484084.656\n",
        "690     480912.632\n",
        "691     475523.424\n",
        "692     470685.960\n",
        "693     462931.272\n",
        "694     455548.688\n",
        "695     453604.624\n",
        "696     454567.104\n",
        "697     451255.528\n",
        "698     451595.272\n",
        "699     453992.936\n",
        "700     454649.880\n",
        "701     457552.336\n",
        "702     461549.256\n",
        "703     463660.784\n",
        "704     482636.912\n",
        "705     489290.672\n",
        "706     495159.016\n",
        "707     503757.840\n",
        "708     522441.608\n",
        "709     541807.248\n",
        "710     573231.536\n",
        "711     618435.880\n",
        "712     672030.536\n",
        "713     742225.064\n",
        "714     844274.944\n",
        "715    1005043.120\n",
        "716    1234767.720\n",
        "717    1546178.280\n",
        "718    1841481.968\n",
        "719    2017894.600\n",
        "Name: mean, dtype: float64"
       ]
      }
     ],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Min_of_Right_Loc['min']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 219,
       "text": [
        "0    489290.672\n",
        "1    623261.048\n",
        "Name: min, dtype: float64"
       ]
      }
     ],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Coefficients = pd.DataFrame({'tan' : [], 'free' : []}, dtype=float)\n",
      "\n",
      "def Line(Min_of_Right_Loc, Min_of_Left_Loc):\n",
      "    for i in df_len:\n",
      "        Coefficients['tan'].loc[i] = (Min_of_Right_Loc['min'].loc[i] - Min_of_Left_Loc['min'].loc[i])/(Min_of_Right_Loc['point'].loc[i] - Min_of_Left_Loc['point'].loc[i])\n",
      "        Coefficients['free'].loc[i] = Min_of_Right_Loc['min'].loc[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Line(Min_of_Right_Loc, Min_of_Left_Loc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Coefficients['tan']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 222,
       "text": [
        "0    2295.503385\n",
        "1    3116.180923\n",
        "Name: tan, dtype: float64"
       ]
      }
     ],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Corr = pd.DataFrame({'Corr' : []}, dtype=float)\n",
      "\n",
      "\n",
      "for i in df_len:\n",
      "    for j in range(LeftBorder, RightBorder, 1):\n",
      "        df_mean_no_normal[i]['mean'].loc[j] = (df_mean_no_normal[i]['mean'].loc[j] - (j-LeftBorder+1)*Coefficients['tan'].loc[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 223
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 223
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_mean_no_normal[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>mean</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>672</th>\n",
        "      <td>468972.736615</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>673</th>\n",
        "      <td>456612.961231</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>674</th>\n",
        "      <td>447566.833846</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>675</th>\n",
        "      <td>436018.130462</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>676</th>\n",
        "      <td>423338.083077</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>677</th>\n",
        "      <td>422654.923692</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>678</th>\n",
        "      <td>414004.364308</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>679</th>\n",
        "      <td>411243.556923</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>680</th>\n",
        "      <td>409952.669538</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>681</th>\n",
        "      <td>409063.830154</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>682</th>\n",
        "      <td>416282.774769</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>683</th>\n",
        "      <td>419919.047385</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>684</th>\n",
        "      <td>425298.376000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>685</th>\n",
        "      <td>431656.912615</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>686</th>\n",
        "      <td>434793.673231</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>687</th>\n",
        "      <td>440137.833846</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>688</th>\n",
        "      <td>442521.738462</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>689</th>\n",
        "      <td>442765.595077</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>690</th>\n",
        "      <td>437298.067692</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>691</th>\n",
        "      <td>429613.356308</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>692</th>\n",
        "      <td>422480.388923</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>693</th>\n",
        "      <td>412430.197538</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>694</th>\n",
        "      <td>402752.110154</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>695</th>\n",
        "      <td>398512.542769</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>696</th>\n",
        "      <td>397179.519385</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>697</th>\n",
        "      <td>391572.440000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>698</th>\n",
        "      <td>389616.680615</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>699</th>\n",
        "      <td>389718.841231</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>700</th>\n",
        "      <td>388080.281846</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>701</th>\n",
        "      <td>388687.234462</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>702</th>\n",
        "      <td>390388.651077</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>703</th>\n",
        "      <td>390204.675692</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>704</th>\n",
        "      <td>406885.300308</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>705</th>\n",
        "      <td>411243.556923</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>706</th>\n",
        "      <td>414816.397538</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>707</th>\n",
        "      <td>421119.718154</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>708</th>\n",
        "      <td>437507.982769</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>709</th>\n",
        "      <td>454578.119385</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>710</th>\n",
        "      <td>483706.904000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>711</th>\n",
        "      <td>526615.744615</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>712</th>\n",
        "      <td>577914.897231</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>713</th>\n",
        "      <td>645813.921846</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>714</th>\n",
        "      <td>745568.298462</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>715</th>\n",
        "      <td>904040.971077</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>716</th>\n",
        "      <td>1131470.067692</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>717</th>\n",
        "      <td>1440585.124308</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>718</th>\n",
        "      <td>1733593.308923</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>719</th>\n",
        "      <td>1907710.437538</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 224,
       "text": [
        "               mean\n",
        "672   468972.736615\n",
        "673   456612.961231\n",
        "674   447566.833846\n",
        "675   436018.130462\n",
        "676   423338.083077\n",
        "677   422654.923692\n",
        "678   414004.364308\n",
        "679   411243.556923\n",
        "680   409952.669538\n",
        "681   409063.830154\n",
        "682   416282.774769\n",
        "683   419919.047385\n",
        "684   425298.376000\n",
        "685   431656.912615\n",
        "686   434793.673231\n",
        "687   440137.833846\n",
        "688   442521.738462\n",
        "689   442765.595077\n",
        "690   437298.067692\n",
        "691   429613.356308\n",
        "692   422480.388923\n",
        "693   412430.197538\n",
        "694   402752.110154\n",
        "695   398512.542769\n",
        "696   397179.519385\n",
        "697   391572.440000\n",
        "698   389616.680615\n",
        "699   389718.841231\n",
        "700   388080.281846\n",
        "701   388687.234462\n",
        "702   390388.651077\n",
        "703   390204.675692\n",
        "704   406885.300308\n",
        "705   411243.556923\n",
        "706   414816.397538\n",
        "707   421119.718154\n",
        "708   437507.982769\n",
        "709   454578.119385\n",
        "710   483706.904000\n",
        "711   526615.744615\n",
        "712   577914.897231\n",
        "713   645813.921846\n",
        "714   745568.298462\n",
        "715   904040.971077\n",
        "716  1131470.067692\n",
        "717  1440585.124308\n",
        "718  1733593.308923\n",
        "719  1907710.437538"
       ]
      }
     ],
     "prompt_number": 224
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_len = xrange(len(df))\n",
      "\n",
      "normalizing(df, df_len)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spectra1\n",
        "spectra2\n",
        "spectra3\n",
        "spectra4\n",
        "spectra5\n",
        "spectra6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "spectra7\n",
        "spectra8\n",
        "spectra9\n",
        "spectra10\n",
        "spectra11\n",
        "spectra12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "spectra13\n",
        "spectra14\n",
        "spectra15\n",
        "spectra16\n",
        "spectra17\n",
        "spectra18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "spectra19\n",
        "spectra20\n",
        "spectra21\n",
        "spectra22\n",
        "spectra23"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "spectra24\n",
        "spectra25\n",
        "spectra1\n",
        "spectra2\n",
        "spectra3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "spectra4\n",
        "spectra5\n",
        "spectra6\n",
        "spectra7\n",
        "spectra8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "spectra9\n",
        "spectra10\n",
        "spectra11\n",
        "spectra12\n",
        "spectra13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "spectra14\n",
        "spectra15\n",
        "spectra16\n",
        "spectra17\n",
        "spectra18\n",
        "spectra19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "spectra20\n",
        "spectra21\n",
        "spectra22\n",
        "spectra23\n",
        "spectra24\n",
        "spectra25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df[1]['spectra1']\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "df_len = xrange(len(df))\n",
      "\n",
      "a = [c for c in xrange(7)]\n",
      "print(a)\n",
      "\n",
      "\n",
      "for i in df_len:\n",
      "    for j in df[i].columns:\n",
      "        if j != 'number':\n",
      "            a = df[i][j].loc[667:673]\n",
      "            print(a)\n",
      "            df[i][j].iloc[0] = a.max()\n",
      "            #print(df[i][j].loc[0])\n",
      "            #print max(a)\n",
      "            \n",
      "#\u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u043e \u0434\u043b\u044f \u043d\u0435\u043d\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e\n",
      "\n",
      "for i in df_len:\n",
      "    for j in df[i].columns:\n",
      "        if j != 'number':\n",
      "            a = df_mean_no_normal[i].loc[667:673]\n",
      "            print(a)\n",
      "            df_mean_no_normal[i].iloc[0] = a.max()\n",
      "            #print(df[i][j].loc[0])\n",
      "            #print max(a)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 1, 2, 3, 4, 5, 6]\n",
        "672    0.037217\n",
        "673    0.022209\n",
        "Name: spectra1, dtype: float64\n",
        "672    0.042628\n",
        "673    0.036403\n",
        "Name: spectra2, dtype: float64\n",
        "672    0.042855\n",
        "673    0.024624\n",
        "Name: spectra3, dtype: float64\n",
        "672    0.025272\n",
        "673    0.020481\n",
        "Name: spectra4, dtype: float64\n",
        "672    0.026362\n",
        "673    0.035553\n",
        "Name: spectra5, dtype: float64\n",
        "672    0.032523\n",
        "673    0.028972\n",
        "Name: spectra6, dtype: float64\n",
        "672    0.039812\n",
        "673    0.043914\n",
        "Name: spectra7, dtype: float64\n",
        "672    0.028776\n",
        "673    0.025444\n",
        "Name: spectra8, dtype: float64\n",
        "672    0.018935\n",
        "673    0.020530\n",
        "Name: spectra9, dtype: float64\n",
        "672    0.051182\n",
        "673    0.046596\n",
        "Name: spectra10, dtype: float64\n",
        "672    0.031666\n",
        "673    0.026326\n",
        "Name: spectra11, dtype: float64\n",
        "672    0.036855\n",
        "673    0.032005\n",
        "Name: spectra12, dtype: float64\n",
        "672    0.035992\n",
        "673    0.018599\n",
        "Name: spectra13, dtype: float64\n",
        "672    0.057479\n",
        "673    0.042705\n",
        "Name: spectra14, dtype: float64\n",
        "672    0.022070\n",
        "673    0.013065\n",
        "Name: spectra15, dtype: float64\n",
        "672    0.015190\n",
        "673    0.016331\n",
        "Name: spectra16, dtype: float64\n",
        "672    0.056767\n",
        "673    0.048259\n",
        "Name: spectra17, dtype: float64\n",
        "672    0.059561\n",
        "673    0.045083\n",
        "Name: spectra18, dtype: float64\n",
        "672    0.017317\n",
        "673    0.005945\n",
        "Name: spectra19, dtype: float64\n",
        "672    0.049428\n",
        "673    0.031930\n",
        "Name: spectra20, dtype: float64\n",
        "672    0.041196\n",
        "673    0.051479\n",
        "Name: spectra21, dtype: float64\n",
        "672    0.038693\n",
        "673    0.039777\n",
        "Name: spectra22, dtype: float64\n",
        "672    0.032531\n",
        "673    0.032679\n",
        "Name: spectra23, dtype: float64\n",
        "672    0.051023\n",
        "673    0.034599\n",
        "Name: spectra24, dtype: float64\n",
        "672    0.044873\n",
        "673    0.034209\n",
        "Name: spectra25, dtype: float64\n",
        "672    0.026432\n",
        "673    0.020946\n",
        "Name: spectra1, dtype: float64\n",
        "672    0.022588\n",
        "673    0.003834\n",
        "Name: spectra2, dtype: float64\n",
        "672    0.002251\n",
        "673    0.007021\n",
        "Name: spectra3, dtype: float64\n",
        "672    0.039332\n",
        "673    0.039419\n",
        "Name: spectra4, dtype: float64\n",
        "672    0.023910\n",
        "673    0.012878\n",
        "Name: spectra5, dtype: float64\n",
        "672    0.025025\n",
        "673    0.021267\n",
        "Name: spectra6, dtype: float64\n",
        "672    0.034775\n",
        "673    0.020334\n",
        "Name: spectra7, dtype: float64\n",
        "672    0.030333\n",
        "673    0.024282\n",
        "Name: spectra8, dtype: float64\n",
        "672    0.019626\n",
        "673    0.009351\n",
        "Name: spectra9, dtype: float64\n",
        "672    0.040301\n",
        "673    0.040047\n",
        "Name: spectra10, dtype: float64\n",
        "672    0.026196\n",
        "673    0.003733\n",
        "Name: spectra11, dtype: float64\n",
        "672    0.046116\n",
        "673    0.030873\n",
        "Name: spectra12, dtype: float64\n",
        "672    0.035643\n",
        "673    0.023165\n",
        "Name: spectra13, dtype: float64\n",
        "672    0.023976\n",
        "673    0.029190\n",
        "Name: spectra14, dtype: float64\n",
        "672    0.064027\n",
        "673    0.053837\n",
        "Name: spectra15, dtype: float64\n",
        "672    0.026358\n",
        "673    0.021003\n",
        "Name: spectra16, dtype: float64\n",
        "672    0.022121\n",
        "673    0.014677\n",
        "Name: spectra17, dtype: float64\n",
        "672    0.01855\n",
        "673    0.00562\n",
        "Name: spectra18, dtype: float64\n",
        "672    0.06063\n",
        "673    0.04093\n",
        "Name: spectra19, dtype: float64\n",
        "672    0.037163\n",
        "673    0.047966\n",
        "Name: spectra20, dtype: float64\n",
        "672    0.054051\n",
        "673    0.050053\n",
        "Name: spectra21, dtype: float64\n",
        "672    0.035466\n",
        "673    0.034048\n",
        "Name: spectra22, dtype: float64\n",
        "672    0.028037\n",
        "673    0.025307\n",
        "Name: spectra23, dtype: float64\n",
        "672    0.045766\n",
        "673    0.052973\n",
        "Name: spectra24, dtype: float64\n",
        "672    0.038804\n",
        "673    0.025231\n",
        "Name: spectra25, dtype: float64\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  468972.736615\n",
        "673  456612.961231\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n",
        "              mean\n",
        "672  581041.107077\n",
        "673  565188.430154\n"
       ]
      }
     ],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 228,
       "text": [
        "mean    581041.107077\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 228
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#df[0]['spectra4'].loc[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 229
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_norm = []\n",
      "x_nonorm = []\n",
      "std = []\n",
      "mean = []\n",
      "\n",
      "for i in df_len:\n",
      "    x_norm.append(np.array(df[i].iloc[0]))\n",
      "    x_nonorm.append(np.array(df_mean_no_normal[i].iloc[0]))\n",
      "    std.append(np.std(x_norm[i]))\n",
      "    mean.append(np.mean(x_norm[i]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_mean_no_normal[0].iloc[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 231,
       "text": [
        "mean    468972.736615\n",
        "Name: 672, dtype: float64"
       ]
      }
     ],
     "prompt_number": 231
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Alert = False\n",
      "for i in df_len:\n",
      "    if(scipy.stats.shapiro(x_norm[i])[1] < 0.05):\n",
      "        Alert = True\n",
      "       \n",
      "print(Alert)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "False\n"
       ]
      }
     ],
     "prompt_number": 232
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>spectra1</th>\n",
        "      <th>spectra2</th>\n",
        "      <th>spectra3</th>\n",
        "      <th>spectra4</th>\n",
        "      <th>spectra5</th>\n",
        "      <th>spectra6</th>\n",
        "      <th>spectra7</th>\n",
        "      <th>spectra8</th>\n",
        "      <th>spectra9</th>\n",
        "      <th>spectra10</th>\n",
        "      <th>...</th>\n",
        "      <th>spectra16</th>\n",
        "      <th>spectra17</th>\n",
        "      <th>spectra18</th>\n",
        "      <th>spectra19</th>\n",
        "      <th>spectra20</th>\n",
        "      <th>spectra21</th>\n",
        "      <th>spectra22</th>\n",
        "      <th>spectra23</th>\n",
        "      <th>spectra24</th>\n",
        "      <th>spectra25</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>672</th>\n",
        "      <td>0.037217</td>\n",
        "      <td>0.042628</td>\n",
        "      <td>0.042855</td>\n",
        "      <td>0.025272</td>\n",
        "      <td>0.035553</td>\n",
        "      <td>0.032523</td>\n",
        "      <td>0.043914</td>\n",
        "      <td>0.028776</td>\n",
        "      <td>0.020530</td>\n",
        "      <td>0.051182</td>\n",
        "      <td>...</td>\n",
        "      <td>0.016331</td>\n",
        "      <td>0.056767</td>\n",
        "      <td>0.059561</td>\n",
        "      <td>0.017317</td>\n",
        "      <td>0.049428</td>\n",
        "      <td>0.051479</td>\n",
        "      <td>0.039777</td>\n",
        "      <td>0.032679</td>\n",
        "      <td>0.051023</td>\n",
        "      <td>0.044873</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>673</th>\n",
        "      <td>0.022209</td>\n",
        "      <td>0.036403</td>\n",
        "      <td>0.024624</td>\n",
        "      <td>0.020481</td>\n",
        "      <td>0.035553</td>\n",
        "      <td>0.028972</td>\n",
        "      <td>0.043914</td>\n",
        "      <td>0.025444</td>\n",
        "      <td>0.020530</td>\n",
        "      <td>0.046596</td>\n",
        "      <td>...</td>\n",
        "      <td>0.016331</td>\n",
        "      <td>0.048259</td>\n",
        "      <td>0.045083</td>\n",
        "      <td>0.005945</td>\n",
        "      <td>0.031930</td>\n",
        "      <td>0.051479</td>\n",
        "      <td>0.039777</td>\n",
        "      <td>0.032679</td>\n",
        "      <td>0.034599</td>\n",
        "      <td>0.034209</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>674</th>\n",
        "      <td>0.020356</td>\n",
        "      <td>0.023375</td>\n",
        "      <td>0.015803</td>\n",
        "      <td>0.007571</td>\n",
        "      <td>0.030597</td>\n",
        "      <td>0.027670</td>\n",
        "      <td>0.045261</td>\n",
        "      <td>0.031771</td>\n",
        "      <td>0.029710</td>\n",
        "      <td>0.029165</td>\n",
        "      <td>...</td>\n",
        "      <td>0.021160</td>\n",
        "      <td>0.053163</td>\n",
        "      <td>0.037622</td>\n",
        "      <td>0.007885</td>\n",
        "      <td>0.030210</td>\n",
        "      <td>0.067232</td>\n",
        "      <td>0.038306</td>\n",
        "      <td>0.023992</td>\n",
        "      <td>0.015429</td>\n",
        "      <td>0.038883</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>675</th>\n",
        "      <td>0.022404</td>\n",
        "      <td>0.010635</td>\n",
        "      <td>0.010161</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.024352</td>\n",
        "      <td>0.018014</td>\n",
        "      <td>0.028492</td>\n",
        "      <td>0.031411</td>\n",
        "      <td>0.024778</td>\n",
        "      <td>0.011001</td>\n",
        "      <td>...</td>\n",
        "      <td>0.017167</td>\n",
        "      <td>0.043780</td>\n",
        "      <td>0.026813</td>\n",
        "      <td>0.015140</td>\n",
        "      <td>0.028529</td>\n",
        "      <td>0.057954</td>\n",
        "      <td>0.034715</td>\n",
        "      <td>0.008884</td>\n",
        "      <td>0.016687</td>\n",
        "      <td>0.032201</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>676</th>\n",
        "      <td>0.012593</td>\n",
        "      <td>0.008774</td>\n",
        "      <td>0.005444</td>\n",
        "      <td>0.005382</td>\n",
        "      <td>0.017201</td>\n",
        "      <td>0.001910</td>\n",
        "      <td>0.006343</td>\n",
        "      <td>0.019035</td>\n",
        "      <td>0.013963</td>\n",
        "      <td>0.005028</td>\n",
        "      <td>...</td>\n",
        "      <td>0.001109</td>\n",
        "      <td>0.026387</td>\n",
        "      <td>0.028496</td>\n",
        "      <td>0.019721</td>\n",
        "      <td>0.029691</td>\n",
        "      <td>0.029528</td>\n",
        "      <td>0.031927</td>\n",
        "      <td>0.008955</td>\n",
        "      <td>0.032154</td>\n",
        "      <td>0.012346</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>677</th>\n",
        "      <td>0.009799</td>\n",
        "      <td>0.003207</td>\n",
        "      <td>0.004616</td>\n",
        "      <td>0.020289</td>\n",
        "      <td>0.004351</td>\n",
        "      <td>0.001589</td>\n",
        "      <td>0.000468</td>\n",
        "      <td>0.018570</td>\n",
        "      <td>0.017503</td>\n",
        "      <td>0.015733</td>\n",
        "      <td>...</td>\n",
        "      <td>0.008979</td>\n",
        "      <td>0.035515</td>\n",
        "      <td>0.031567</td>\n",
        "      <td>0.029363</td>\n",
        "      <td>0.031893</td>\n",
        "      <td>0.012711</td>\n",
        "      <td>0.032258</td>\n",
        "      <td>0.013371</td>\n",
        "      <td>0.046418</td>\n",
        "      <td>0.010671</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>678</th>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.018392</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.011365</td>\n",
        "      <td>0.005447</td>\n",
        "      <td>0.023101</td>\n",
        "      <td>0.006296</td>\n",
        "      <td>0.011117</td>\n",
        "      <td>...</td>\n",
        "      <td>0.020100</td>\n",
        "      <td>0.034827</td>\n",
        "      <td>0.021374</td>\n",
        "      <td>0.025503</td>\n",
        "      <td>0.030501</td>\n",
        "      <td>0.000809</td>\n",
        "      <td>0.011124</td>\n",
        "      <td>0.015955</td>\n",
        "      <td>0.037785</td>\n",
        "      <td>0.006831</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>679</th>\n",
        "      <td>0.006323</td>\n",
        "      <td>0.012310</td>\n",
        "      <td>0.007492</td>\n",
        "      <td>0.021288</td>\n",
        "      <td>0.002389</td>\n",
        "      <td>0.018396</td>\n",
        "      <td>0.011607</td>\n",
        "      <td>0.012339</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>0.028280</td>\n",
        "      <td>0.025953</td>\n",
        "      <td>0.015376</td>\n",
        "      <td>0.017229</td>\n",
        "      <td>0.037705</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.002174</td>\n",
        "      <td>0.011832</td>\n",
        "      <td>0.021636</td>\n",
        "      <td>0.005015</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>680</th>\n",
        "      <td>0.010508</td>\n",
        "      <td>0.011362</td>\n",
        "      <td>0.022161</td>\n",
        "      <td>0.022923</td>\n",
        "      <td>0.008187</td>\n",
        "      <td>0.016630</td>\n",
        "      <td>0.017223</td>\n",
        "      <td>0.000641</td>\n",
        "      <td>0.013201</td>\n",
        "      <td>0.005104</td>\n",
        "      <td>...</td>\n",
        "      <td>0.017412</td>\n",
        "      <td>0.017833</td>\n",
        "      <td>0.011430</td>\n",
        "      <td>0.007938</td>\n",
        "      <td>0.028417</td>\n",
        "      <td>0.007232</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.003676</td>\n",
        "      <td>0.008373</td>\n",
        "      <td>0.008504</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>681</th>\n",
        "      <td>0.016237</td>\n",
        "      <td>0.013915</td>\n",
        "      <td>0.030690</td>\n",
        "      <td>0.031889</td>\n",
        "      <td>0.020170</td>\n",
        "      <td>0.004343</td>\n",
        "      <td>0.017014</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.008616</td>\n",
        "      <td>0.018650</td>\n",
        "      <td>...</td>\n",
        "      <td>0.006659</td>\n",
        "      <td>0.010570</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.003503</td>\n",
        "      <td>0.015920</td>\n",
        "      <td>0.013317</td>\n",
        "      <td>0.003774</td>\n",
        "      <td>0.006838</td>\n",
        "      <td>0.020073</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>682</th>\n",
        "      <td>0.028294</td>\n",
        "      <td>0.025454</td>\n",
        "      <td>0.026262</td>\n",
        "      <td>0.037954</td>\n",
        "      <td>0.028586</td>\n",
        "      <td>0.002378</td>\n",
        "      <td>0.024196</td>\n",
        "      <td>0.013676</td>\n",
        "      <td>0.004357</td>\n",
        "      <td>0.014718</td>\n",
        "      <td>...</td>\n",
        "      <td>0.005296</td>\n",
        "      <td>0.009402</td>\n",
        "      <td>0.004887</td>\n",
        "      <td>0.002060</td>\n",
        "      <td>0.013676</td>\n",
        "      <td>0.017262</td>\n",
        "      <td>0.019083</td>\n",
        "      <td>0.023764</td>\n",
        "      <td>0.030163</td>\n",
        "      <td>0.015951</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>683</th>\n",
        "      <td>0.033730</td>\n",
        "      <td>0.024377</td>\n",
        "      <td>0.015378</td>\n",
        "      <td>0.032024</td>\n",
        "      <td>0.031223</td>\n",
        "      <td>0.003870</td>\n",
        "      <td>0.029476</td>\n",
        "      <td>0.022601</td>\n",
        "      <td>0.021732</td>\n",
        "      <td>0.012845</td>\n",
        "      <td>...</td>\n",
        "      <td>0.001802</td>\n",
        "      <td>0.014316</td>\n",
        "      <td>0.025680</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.026892</td>\n",
        "      <td>0.009361</td>\n",
        "      <td>0.022409</td>\n",
        "      <td>0.036504</td>\n",
        "      <td>0.027715</td>\n",
        "      <td>0.029956</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>684</th>\n",
        "      <td>0.044509</td>\n",
        "      <td>0.031477</td>\n",
        "      <td>0.013379</td>\n",
        "      <td>0.037952</td>\n",
        "      <td>0.043084</td>\n",
        "      <td>0.006766</td>\n",
        "      <td>0.033623</td>\n",
        "      <td>0.026169</td>\n",
        "      <td>0.031574</td>\n",
        "      <td>0.025397</td>\n",
        "      <td>...</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.029773</td>\n",
        "      <td>0.029969</td>\n",
        "      <td>0.010051</td>\n",
        "      <td>0.042146</td>\n",
        "      <td>0.009884</td>\n",
        "      <td>0.038315</td>\n",
        "      <td>0.031910</td>\n",
        "      <td>0.028349</td>\n",
        "      <td>0.038308</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>685</th>\n",
        "      <td>0.041940</td>\n",
        "      <td>0.043196</td>\n",
        "      <td>0.025642</td>\n",
        "      <td>0.054181</td>\n",
        "      <td>0.046403</td>\n",
        "      <td>0.009683</td>\n",
        "      <td>0.026496</td>\n",
        "      <td>0.031467</td>\n",
        "      <td>0.027935</td>\n",
        "      <td>0.035053</td>\n",
        "      <td>...</td>\n",
        "      <td>0.010538</td>\n",
        "      <td>0.019027</td>\n",
        "      <td>0.029682</td>\n",
        "      <td>0.017743</td>\n",
        "      <td>0.052460</td>\n",
        "      <td>0.027488</td>\n",
        "      <td>0.060952</td>\n",
        "      <td>0.018416</td>\n",
        "      <td>0.028537</td>\n",
        "      <td>0.056217</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>686</th>\n",
        "      <td>0.029312</td>\n",
        "      <td>0.047693</td>\n",
        "      <td>0.051402</td>\n",
        "      <td>0.064255</td>\n",
        "      <td>0.044641</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.023334</td>\n",
        "      <td>0.035049</td>\n",
        "      <td>0.023412</td>\n",
        "      <td>0.035420</td>\n",
        "      <td>...</td>\n",
        "      <td>0.019230</td>\n",
        "      <td>0.015514</td>\n",
        "      <td>0.025152</td>\n",
        "      <td>0.020610</td>\n",
        "      <td>0.052727</td>\n",
        "      <td>0.037284</td>\n",
        "      <td>0.066906</td>\n",
        "      <td>0.009940</td>\n",
        "      <td>0.037993</td>\n",
        "      <td>0.066328</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>687</th>\n",
        "      <td>0.036121</td>\n",
        "      <td>0.043517</td>\n",
        "      <td>0.054339</td>\n",
        "      <td>0.063194</td>\n",
        "      <td>0.048490</td>\n",
        "      <td>0.005249</td>\n",
        "      <td>0.025532</td>\n",
        "      <td>0.035454</td>\n",
        "      <td>0.030541</td>\n",
        "      <td>0.034787</td>\n",
        "      <td>...</td>\n",
        "      <td>0.028699</td>\n",
        "      <td>0.029603</td>\n",
        "      <td>0.033139</td>\n",
        "      <td>0.027176</td>\n",
        "      <td>0.040567</td>\n",
        "      <td>0.052778</td>\n",
        "      <td>0.059721</td>\n",
        "      <td>0.027869</td>\n",
        "      <td>0.045149</td>\n",
        "      <td>0.062281</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>688</th>\n",
        "      <td>0.050722</td>\n",
        "      <td>0.044839</td>\n",
        "      <td>0.051790</td>\n",
        "      <td>0.056904</td>\n",
        "      <td>0.039364</td>\n",
        "      <td>0.016819</td>\n",
        "      <td>0.025348</td>\n",
        "      <td>0.031553</td>\n",
        "      <td>0.044170</td>\n",
        "      <td>0.032273</td>\n",
        "      <td>...</td>\n",
        "      <td>0.043947</td>\n",
        "      <td>0.048417</td>\n",
        "      <td>0.040031</td>\n",
        "      <td>0.046387</td>\n",
        "      <td>0.026818</td>\n",
        "      <td>0.062390</td>\n",
        "      <td>0.048813</td>\n",
        "      <td>0.043412</td>\n",
        "      <td>0.047568</td>\n",
        "      <td>0.060425</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>689</th>\n",
        "      <td>0.054222</td>\n",
        "      <td>0.066100</td>\n",
        "      <td>0.045877</td>\n",
        "      <td>0.066135</td>\n",
        "      <td>0.036163</td>\n",
        "      <td>0.026049</td>\n",
        "      <td>0.029347</td>\n",
        "      <td>0.043293</td>\n",
        "      <td>0.044445</td>\n",
        "      <td>0.027179</td>\n",
        "      <td>...</td>\n",
        "      <td>0.043938</td>\n",
        "      <td>0.057789</td>\n",
        "      <td>0.053331</td>\n",
        "      <td>0.045274</td>\n",
        "      <td>0.039365</td>\n",
        "      <td>0.043874</td>\n",
        "      <td>0.040361</td>\n",
        "      <td>0.042484</td>\n",
        "      <td>0.057504</td>\n",
        "      <td>0.064650</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>690</th>\n",
        "      <td>0.043935</td>\n",
        "      <td>0.095575</td>\n",
        "      <td>0.048626</td>\n",
        "      <td>0.062397</td>\n",
        "      <td>0.029433</td>\n",
        "      <td>0.027465</td>\n",
        "      <td>0.010720</td>\n",
        "      <td>0.050648</td>\n",
        "      <td>0.035167</td>\n",
        "      <td>0.030155</td>\n",
        "      <td>...</td>\n",
        "      <td>0.032601</td>\n",
        "      <td>0.054757</td>\n",
        "      <td>0.056899</td>\n",
        "      <td>0.033517</td>\n",
        "      <td>0.046227</td>\n",
        "      <td>0.024340</td>\n",
        "      <td>0.040550</td>\n",
        "      <td>0.038985</td>\n",
        "      <td>0.059328</td>\n",
        "      <td>0.073344</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>691</th>\n",
        "      <td>0.044670</td>\n",
        "      <td>0.090199</td>\n",
        "      <td>0.059187</td>\n",
        "      <td>0.049636</td>\n",
        "      <td>0.022346</td>\n",
        "      <td>0.029477</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.058595</td>\n",
        "      <td>0.034005</td>\n",
        "      <td>0.028783</td>\n",
        "      <td>...</td>\n",
        "      <td>0.024702</td>\n",
        "      <td>0.028824</td>\n",
        "      <td>0.055560</td>\n",
        "      <td>0.014946</td>\n",
        "      <td>0.027317</td>\n",
        "      <td>0.030857</td>\n",
        "      <td>0.031756</td>\n",
        "      <td>0.037989</td>\n",
        "      <td>0.046759</td>\n",
        "      <td>0.085942</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>692</th>\n",
        "      <td>0.042678</td>\n",
        "      <td>0.066789</td>\n",
        "      <td>0.046648</td>\n",
        "      <td>0.031474</td>\n",
        "      <td>0.032154</td>\n",
        "      <td>0.030738</td>\n",
        "      <td>0.006457</td>\n",
        "      <td>0.055001</td>\n",
        "      <td>0.044087</td>\n",
        "      <td>0.028802</td>\n",
        "      <td>...</td>\n",
        "      <td>0.027106</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.061387</td>\n",
        "      <td>0.016890</td>\n",
        "      <td>0.018052</td>\n",
        "      <td>0.045816</td>\n",
        "      <td>0.037742</td>\n",
        "      <td>0.038735</td>\n",
        "      <td>0.040076</td>\n",
        "      <td>0.073989</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>693</th>\n",
        "      <td>0.030165</td>\n",
        "      <td>0.042092</td>\n",
        "      <td>0.027145</td>\n",
        "      <td>0.018202</td>\n",
        "      <td>0.038294</td>\n",
        "      <td>0.014924</td>\n",
        "      <td>0.010354</td>\n",
        "      <td>0.040773</td>\n",
        "      <td>0.036527</td>\n",
        "      <td>0.020127</td>\n",
        "      <td>...</td>\n",
        "      <td>0.030615</td>\n",
        "      <td>0.003223</td>\n",
        "      <td>0.066457</td>\n",
        "      <td>0.019064</td>\n",
        "      <td>0.024672</td>\n",
        "      <td>0.043705</td>\n",
        "      <td>0.041751</td>\n",
        "      <td>0.033869</td>\n",
        "      <td>0.036140</td>\n",
        "      <td>0.064670</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>694</th>\n",
        "      <td>0.030523</td>\n",
        "      <td>0.035805</td>\n",
        "      <td>0.019054</td>\n",
        "      <td>0.018969</td>\n",
        "      <td>0.037530</td>\n",
        "      <td>0.006404</td>\n",
        "      <td>0.020029</td>\n",
        "      <td>0.024884</td>\n",
        "      <td>0.021907</td>\n",
        "      <td>0.008233</td>\n",
        "      <td>...</td>\n",
        "      <td>0.012424</td>\n",
        "      <td>0.023411</td>\n",
        "      <td>0.061448</td>\n",
        "      <td>0.017831</td>\n",
        "      <td>0.015082</td>\n",
        "      <td>0.018973</td>\n",
        "      <td>0.037189</td>\n",
        "      <td>0.019196</td>\n",
        "      <td>0.034919</td>\n",
        "      <td>0.060791</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>695</th>\n",
        "      <td>0.030675</td>\n",
        "      <td>0.037350</td>\n",
        "      <td>0.016521</td>\n",
        "      <td>0.019691</td>\n",
        "      <td>0.046888</td>\n",
        "      <td>0.006561</td>\n",
        "      <td>0.013509</td>\n",
        "      <td>0.020898</td>\n",
        "      <td>0.019541</td>\n",
        "      <td>0.012476</td>\n",
        "      <td>...</td>\n",
        "      <td>0.011202</td>\n",
        "      <td>0.034810</td>\n",
        "      <td>0.054667</td>\n",
        "      <td>0.023373</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.004889</td>\n",
        "      <td>0.034870</td>\n",
        "      <td>0.017676</td>\n",
        "      <td>0.030324</td>\n",
        "      <td>0.055753</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>696</th>\n",
        "      <td>0.015213</td>\n",
        "      <td>0.035534</td>\n",
        "      <td>0.013704</td>\n",
        "      <td>0.021559</td>\n",
        "      <td>0.052132</td>\n",
        "      <td>0.006087</td>\n",
        "      <td>0.016061</td>\n",
        "      <td>0.021661</td>\n",
        "      <td>0.032291</td>\n",
        "      <td>0.016703</td>\n",
        "      <td>...</td>\n",
        "      <td>0.012365</td>\n",
        "      <td>0.041134</td>\n",
        "      <td>0.062101</td>\n",
        "      <td>0.040823</td>\n",
        "      <td>0.004030</td>\n",
        "      <td>0.007303</td>\n",
        "      <td>0.015056</td>\n",
        "      <td>0.032052</td>\n",
        "      <td>0.026719</td>\n",
        "      <td>0.064800</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>697</th>\n",
        "      <td>0.009294</td>\n",
        "      <td>0.029404</td>\n",
        "      <td>0.010319</td>\n",
        "      <td>0.026816</td>\n",
        "      <td>0.036316</td>\n",
        "      <td>0.005322</td>\n",
        "      <td>0.015921</td>\n",
        "      <td>0.021048</td>\n",
        "      <td>0.030038</td>\n",
        "      <td>0.029577</td>\n",
        "      <td>...</td>\n",
        "      <td>0.017055</td>\n",
        "      <td>0.031117</td>\n",
        "      <td>0.068321</td>\n",
        "      <td>0.044947</td>\n",
        "      <td>0.008266</td>\n",
        "      <td>0.016372</td>\n",
        "      <td>0.008328</td>\n",
        "      <td>0.034816</td>\n",
        "      <td>0.030959</td>\n",
        "      <td>0.061212</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>698</th>\n",
        "      <td>0.016460</td>\n",
        "      <td>0.023177</td>\n",
        "      <td>0.008780</td>\n",
        "      <td>0.027274</td>\n",
        "      <td>0.034482</td>\n",
        "      <td>0.012093</td>\n",
        "      <td>0.006264</td>\n",
        "      <td>0.027016</td>\n",
        "      <td>0.019022</td>\n",
        "      <td>0.037230</td>\n",
        "      <td>...</td>\n",
        "      <td>0.029905</td>\n",
        "      <td>0.022777</td>\n",
        "      <td>0.071881</td>\n",
        "      <td>0.029277</td>\n",
        "      <td>0.020425</td>\n",
        "      <td>0.031009</td>\n",
        "      <td>0.007880</td>\n",
        "      <td>0.018684</td>\n",
        "      <td>0.035724</td>\n",
        "      <td>0.044501</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>699</th>\n",
        "      <td>0.020561</td>\n",
        "      <td>0.017215</td>\n",
        "      <td>0.017295</td>\n",
        "      <td>0.021323</td>\n",
        "      <td>0.044168</td>\n",
        "      <td>0.010262</td>\n",
        "      <td>0.008538</td>\n",
        "      <td>0.027450</td>\n",
        "      <td>0.029516</td>\n",
        "      <td>0.027304</td>\n",
        "      <td>...</td>\n",
        "      <td>0.028497</td>\n",
        "      <td>0.022550</td>\n",
        "      <td>0.078326</td>\n",
        "      <td>0.017380</td>\n",
        "      <td>0.038597</td>\n",
        "      <td>0.040408</td>\n",
        "      <td>0.009210</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.032511</td>\n",
        "      <td>0.037674</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>700</th>\n",
        "      <td>0.027824</td>\n",
        "      <td>0.009726</td>\n",
        "      <td>0.026813</td>\n",
        "      <td>0.030858</td>\n",
        "      <td>0.057100</td>\n",
        "      <td>0.004963</td>\n",
        "      <td>0.008244</td>\n",
        "      <td>0.019720</td>\n",
        "      <td>0.030583</td>\n",
        "      <td>0.019016</td>\n",
        "      <td>...</td>\n",
        "      <td>0.028988</td>\n",
        "      <td>0.018673</td>\n",
        "      <td>0.073237</td>\n",
        "      <td>0.030332</td>\n",
        "      <td>0.050279</td>\n",
        "      <td>0.028242</td>\n",
        "      <td>0.018149</td>\n",
        "      <td>0.003259</td>\n",
        "      <td>0.021431</td>\n",
        "      <td>0.032603</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>701</th>\n",
        "      <td>0.034411</td>\n",
        "      <td>0.013310</td>\n",
        "      <td>0.029844</td>\n",
        "      <td>0.032418</td>\n",
        "      <td>0.056895</td>\n",
        "      <td>0.009425</td>\n",
        "      <td>0.007286</td>\n",
        "      <td>0.017802</td>\n",
        "      <td>0.032804</td>\n",
        "      <td>0.030611</td>\n",
        "      <td>...</td>\n",
        "      <td>0.025056</td>\n",
        "      <td>0.035481</td>\n",
        "      <td>0.069981</td>\n",
        "      <td>0.045300</td>\n",
        "      <td>0.044387</td>\n",
        "      <td>0.020432</td>\n",
        "      <td>0.025139</td>\n",
        "      <td>0.013964</td>\n",
        "      <td>0.003038</td>\n",
        "      <td>0.025448</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>702</th>\n",
        "      <td>0.043856</td>\n",
        "      <td>0.030607</td>\n",
        "      <td>0.029160</td>\n",
        "      <td>0.029438</td>\n",
        "      <td>0.046099</td>\n",
        "      <td>0.012303</td>\n",
        "      <td>0.020760</td>\n",
        "      <td>0.016219</td>\n",
        "      <td>0.035723</td>\n",
        "      <td>0.038211</td>\n",
        "      <td>...</td>\n",
        "      <td>0.015627</td>\n",
        "      <td>0.053353</td>\n",
        "      <td>0.069422</td>\n",
        "      <td>0.048023</td>\n",
        "      <td>0.036956</td>\n",
        "      <td>0.035026</td>\n",
        "      <td>0.036948</td>\n",
        "      <td>0.022434</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.033601</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>703</th>\n",
        "      <td>0.053614</td>\n",
        "      <td>0.034781</td>\n",
        "      <td>0.024181</td>\n",
        "      <td>0.031273</td>\n",
        "      <td>0.048368</td>\n",
        "      <td>0.020015</td>\n",
        "      <td>0.028729</td>\n",
        "      <td>0.020474</td>\n",
        "      <td>0.031408</td>\n",
        "      <td>0.048833</td>\n",
        "      <td>...</td>\n",
        "      <td>0.017146</td>\n",
        "      <td>0.047307</td>\n",
        "      <td>0.066169</td>\n",
        "      <td>0.042917</td>\n",
        "      <td>0.053072</td>\n",
        "      <td>0.033601</td>\n",
        "      <td>0.037562</td>\n",
        "      <td>0.024826</td>\n",
        "      <td>0.011513</td>\n",
        "      <td>0.030191</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>704</th>\n",
        "      <td>0.053173</td>\n",
        "      <td>0.042496</td>\n",
        "      <td>0.041244</td>\n",
        "      <td>0.041071</td>\n",
        "      <td>0.059329</td>\n",
        "      <td>0.039795</td>\n",
        "      <td>0.031753</td>\n",
        "      <td>0.028250</td>\n",
        "      <td>0.044165</td>\n",
        "      <td>0.071494</td>\n",
        "      <td>...</td>\n",
        "      <td>0.030459</td>\n",
        "      <td>0.071060</td>\n",
        "      <td>0.076743</td>\n",
        "      <td>0.055389</td>\n",
        "      <td>0.077787</td>\n",
        "      <td>0.036892</td>\n",
        "      <td>0.043521</td>\n",
        "      <td>0.030098</td>\n",
        "      <td>0.035352</td>\n",
        "      <td>0.032496</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>705</th>\n",
        "      <td>0.050943</td>\n",
        "      <td>0.060420</td>\n",
        "      <td>0.052791</td>\n",
        "      <td>0.055973</td>\n",
        "      <td>0.052274</td>\n",
        "      <td>0.042389</td>\n",
        "      <td>0.035578</td>\n",
        "      <td>0.037465</td>\n",
        "      <td>0.046649</td>\n",
        "      <td>0.082897</td>\n",
        "      <td>...</td>\n",
        "      <td>0.024858</td>\n",
        "      <td>0.075074</td>\n",
        "      <td>0.086447</td>\n",
        "      <td>0.065453</td>\n",
        "      <td>0.063709</td>\n",
        "      <td>0.041639</td>\n",
        "      <td>0.044660</td>\n",
        "      <td>0.032664</td>\n",
        "      <td>0.045543</td>\n",
        "      <td>0.037055</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>706</th>\n",
        "      <td>0.072069</td>\n",
        "      <td>0.072675</td>\n",
        "      <td>0.052823</td>\n",
        "      <td>0.071421</td>\n",
        "      <td>0.050409</td>\n",
        "      <td>0.042590</td>\n",
        "      <td>0.045525</td>\n",
        "      <td>0.044689</td>\n",
        "      <td>0.058132</td>\n",
        "      <td>0.077872</td>\n",
        "      <td>...</td>\n",
        "      <td>0.030323</td>\n",
        "      <td>0.058792</td>\n",
        "      <td>0.074710</td>\n",
        "      <td>0.071633</td>\n",
        "      <td>0.047115</td>\n",
        "      <td>0.044530</td>\n",
        "      <td>0.052481</td>\n",
        "      <td>0.039362</td>\n",
        "      <td>0.048557</td>\n",
        "      <td>0.035329</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>707</th>\n",
        "      <td>0.077163</td>\n",
        "      <td>0.069848</td>\n",
        "      <td>0.062215</td>\n",
        "      <td>0.082706</td>\n",
        "      <td>0.056369</td>\n",
        "      <td>0.043347</td>\n",
        "      <td>0.049044</td>\n",
        "      <td>0.040764</td>\n",
        "      <td>0.059685</td>\n",
        "      <td>0.065055</td>\n",
        "      <td>...</td>\n",
        "      <td>0.050061</td>\n",
        "      <td>0.056718</td>\n",
        "      <td>0.073164</td>\n",
        "      <td>0.071142</td>\n",
        "      <td>0.051547</td>\n",
        "      <td>0.044897</td>\n",
        "      <td>0.063092</td>\n",
        "      <td>0.046093</td>\n",
        "      <td>0.046245</td>\n",
        "      <td>0.037006</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>708</th>\n",
        "      <td>0.081982</td>\n",
        "      <td>0.069438</td>\n",
        "      <td>0.078841</td>\n",
        "      <td>0.086611</td>\n",
        "      <td>0.079127</td>\n",
        "      <td>0.043915</td>\n",
        "      <td>0.074054</td>\n",
        "      <td>0.044876</td>\n",
        "      <td>0.070054</td>\n",
        "      <td>0.074366</td>\n",
        "      <td>...</td>\n",
        "      <td>0.058827</td>\n",
        "      <td>0.069892</td>\n",
        "      <td>0.086809</td>\n",
        "      <td>0.073532</td>\n",
        "      <td>0.063573</td>\n",
        "      <td>0.054162</td>\n",
        "      <td>0.075192</td>\n",
        "      <td>0.055702</td>\n",
        "      <td>0.051065</td>\n",
        "      <td>0.047969</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>709</th>\n",
        "      <td>0.094514</td>\n",
        "      <td>0.073215</td>\n",
        "      <td>0.089470</td>\n",
        "      <td>0.092221</td>\n",
        "      <td>0.090868</td>\n",
        "      <td>0.060300</td>\n",
        "      <td>0.088312</td>\n",
        "      <td>0.052152</td>\n",
        "      <td>0.088212</td>\n",
        "      <td>0.086267</td>\n",
        "      <td>...</td>\n",
        "      <td>0.073426</td>\n",
        "      <td>0.082583</td>\n",
        "      <td>0.089511</td>\n",
        "      <td>0.085854</td>\n",
        "      <td>0.075320</td>\n",
        "      <td>0.057579</td>\n",
        "      <td>0.083363</td>\n",
        "      <td>0.075309</td>\n",
        "      <td>0.065243</td>\n",
        "      <td>0.053278</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>710</th>\n",
        "      <td>0.107791</td>\n",
        "      <td>0.100121</td>\n",
        "      <td>0.113278</td>\n",
        "      <td>0.108582</td>\n",
        "      <td>0.115651</td>\n",
        "      <td>0.086994</td>\n",
        "      <td>0.101025</td>\n",
        "      <td>0.065347</td>\n",
        "      <td>0.112814</td>\n",
        "      <td>0.105283</td>\n",
        "      <td>...</td>\n",
        "      <td>0.103964</td>\n",
        "      <td>0.100447</td>\n",
        "      <td>0.095488</td>\n",
        "      <td>0.105069</td>\n",
        "      <td>0.097719</td>\n",
        "      <td>0.068278</td>\n",
        "      <td>0.093066</td>\n",
        "      <td>0.095278</td>\n",
        "      <td>0.084113</td>\n",
        "      <td>0.073279</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>711</th>\n",
        "      <td>0.138536</td>\n",
        "      <td>0.143042</td>\n",
        "      <td>0.149614</td>\n",
        "      <td>0.143593</td>\n",
        "      <td>0.146349</td>\n",
        "      <td>0.115075</td>\n",
        "      <td>0.127445</td>\n",
        "      <td>0.101149</td>\n",
        "      <td>0.134100</td>\n",
        "      <td>0.136338</td>\n",
        "      <td>...</td>\n",
        "      <td>0.138100</td>\n",
        "      <td>0.135503</td>\n",
        "      <td>0.111481</td>\n",
        "      <td>0.117460</td>\n",
        "      <td>0.134495</td>\n",
        "      <td>0.101466</td>\n",
        "      <td>0.115742</td>\n",
        "      <td>0.109436</td>\n",
        "      <td>0.094553</td>\n",
        "      <td>0.103927</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>712</th>\n",
        "      <td>0.176436</td>\n",
        "      <td>0.185135</td>\n",
        "      <td>0.206127</td>\n",
        "      <td>0.201152</td>\n",
        "      <td>0.175077</td>\n",
        "      <td>0.150211</td>\n",
        "      <td>0.157050</td>\n",
        "      <td>0.140341</td>\n",
        "      <td>0.149804</td>\n",
        "      <td>0.160035</td>\n",
        "      <td>...</td>\n",
        "      <td>0.165707</td>\n",
        "      <td>0.186528</td>\n",
        "      <td>0.138849</td>\n",
        "      <td>0.146000</td>\n",
        "      <td>0.177008</td>\n",
        "      <td>0.136876</td>\n",
        "      <td>0.150064</td>\n",
        "      <td>0.141683</td>\n",
        "      <td>0.114005</td>\n",
        "      <td>0.131441</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>713</th>\n",
        "      <td>0.210867</td>\n",
        "      <td>0.237449</td>\n",
        "      <td>0.256136</td>\n",
        "      <td>0.271831</td>\n",
        "      <td>0.216952</td>\n",
        "      <td>0.203890</td>\n",
        "      <td>0.202297</td>\n",
        "      <td>0.183816</td>\n",
        "      <td>0.194049</td>\n",
        "      <td>0.191060</td>\n",
        "      <td>...</td>\n",
        "      <td>0.206971</td>\n",
        "      <td>0.237295</td>\n",
        "      <td>0.175586</td>\n",
        "      <td>0.201067</td>\n",
        "      <td>0.231865</td>\n",
        "      <td>0.167677</td>\n",
        "      <td>0.188365</td>\n",
        "      <td>0.185633</td>\n",
        "      <td>0.152328</td>\n",
        "      <td>0.176600</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>714</th>\n",
        "      <td>0.267861</td>\n",
        "      <td>0.297873</td>\n",
        "      <td>0.323736</td>\n",
        "      <td>0.331764</td>\n",
        "      <td>0.290727</td>\n",
        "      <td>0.279051</td>\n",
        "      <td>0.278205</td>\n",
        "      <td>0.236931</td>\n",
        "      <td>0.267634</td>\n",
        "      <td>0.271136</td>\n",
        "      <td>...</td>\n",
        "      <td>0.262264</td>\n",
        "      <td>0.300364</td>\n",
        "      <td>0.235082</td>\n",
        "      <td>0.282160</td>\n",
        "      <td>0.289154</td>\n",
        "      <td>0.230782</td>\n",
        "      <td>0.239356</td>\n",
        "      <td>0.240059</td>\n",
        "      <td>0.217934</td>\n",
        "      <td>0.235999</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>715</th>\n",
        "      <td>0.375097</td>\n",
        "      <td>0.389569</td>\n",
        "      <td>0.436135</td>\n",
        "      <td>0.429389</td>\n",
        "      <td>0.419035</td>\n",
        "      <td>0.394232</td>\n",
        "      <td>0.385442</td>\n",
        "      <td>0.319149</td>\n",
        "      <td>0.353547</td>\n",
        "      <td>0.387385</td>\n",
        "      <td>...</td>\n",
        "      <td>0.357385</td>\n",
        "      <td>0.391620</td>\n",
        "      <td>0.339856</td>\n",
        "      <td>0.378186</td>\n",
        "      <td>0.392391</td>\n",
        "      <td>0.339553</td>\n",
        "      <td>0.330507</td>\n",
        "      <td>0.314801</td>\n",
        "      <td>0.317851</td>\n",
        "      <td>0.334975</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>716</th>\n",
        "      <td>0.530477</td>\n",
        "      <td>0.520903</td>\n",
        "      <td>0.593893</td>\n",
        "      <td>0.569667</td>\n",
        "      <td>0.578608</td>\n",
        "      <td>0.520847</td>\n",
        "      <td>0.545637</td>\n",
        "      <td>0.456520</td>\n",
        "      <td>0.487118</td>\n",
        "      <td>0.516781</td>\n",
        "      <td>...</td>\n",
        "      <td>0.513193</td>\n",
        "      <td>0.520978</td>\n",
        "      <td>0.481048</td>\n",
        "      <td>0.504511</td>\n",
        "      <td>0.539673</td>\n",
        "      <td>0.488397</td>\n",
        "      <td>0.462871</td>\n",
        "      <td>0.440870</td>\n",
        "      <td>0.450708</td>\n",
        "      <td>0.479189</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>717</th>\n",
        "      <td>0.723902</td>\n",
        "      <td>0.709542</td>\n",
        "      <td>0.777529</td>\n",
        "      <td>0.770316</td>\n",
        "      <td>0.778163</td>\n",
        "      <td>0.698289</td>\n",
        "      <td>0.750038</td>\n",
        "      <td>0.653043</td>\n",
        "      <td>0.689657</td>\n",
        "      <td>0.684997</td>\n",
        "      <td>...</td>\n",
        "      <td>0.709797</td>\n",
        "      <td>0.683749</td>\n",
        "      <td>0.663436</td>\n",
        "      <td>0.689099</td>\n",
        "      <td>0.717148</td>\n",
        "      <td>0.679078</td>\n",
        "      <td>0.678106</td>\n",
        "      <td>0.643080</td>\n",
        "      <td>0.660923</td>\n",
        "      <td>0.676654</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>718</th>\n",
        "      <td>0.892645</td>\n",
        "      <td>0.890009</td>\n",
        "      <td>0.921096</td>\n",
        "      <td>0.921805</td>\n",
        "      <td>0.923914</td>\n",
        "      <td>0.891495</td>\n",
        "      <td>0.906542</td>\n",
        "      <td>0.870164</td>\n",
        "      <td>0.877555</td>\n",
        "      <td>0.869252</td>\n",
        "      <td>...</td>\n",
        "      <td>0.903380</td>\n",
        "      <td>0.864588</td>\n",
        "      <td>0.878948</td>\n",
        "      <td>0.886192</td>\n",
        "      <td>0.879085</td>\n",
        "      <td>0.883214</td>\n",
        "      <td>0.897791</td>\n",
        "      <td>0.873885</td>\n",
        "      <td>0.876304</td>\n",
        "      <td>0.867436</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>719</th>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>...</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>48 rows \u00d7 25 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 233,
       "text": [
        "     spectra1  spectra2  spectra3  spectra4  spectra5  spectra6  spectra7  \\\n",
        "672  0.037217  0.042628  0.042855  0.025272  0.035553  0.032523  0.043914   \n",
        "673  0.022209  0.036403  0.024624  0.020481  0.035553  0.028972  0.043914   \n",
        "674  0.020356  0.023375  0.015803  0.007571  0.030597  0.027670  0.045261   \n",
        "675  0.022404  0.010635  0.010161  0.000000  0.024352  0.018014  0.028492   \n",
        "676  0.012593  0.008774  0.005444  0.005382  0.017201  0.001910  0.006343   \n",
        "677  0.009799  0.003207  0.004616  0.020289  0.004351  0.001589  0.000468   \n",
        "678  0.000000  0.000000  0.000000  0.018392  0.000000  0.011365  0.005447   \n",
        "679  0.006323  0.012310  0.007492  0.021288  0.002389  0.018396  0.011607   \n",
        "680  0.010508  0.011362  0.022161  0.022923  0.008187  0.016630  0.017223   \n",
        "681  0.016237  0.013915  0.030690  0.031889  0.020170  0.004343  0.017014   \n",
        "682  0.028294  0.025454  0.026262  0.037954  0.028586  0.002378  0.024196   \n",
        "683  0.033730  0.024377  0.015378  0.032024  0.031223  0.003870  0.029476   \n",
        "684  0.044509  0.031477  0.013379  0.037952  0.043084  0.006766  0.033623   \n",
        "685  0.041940  0.043196  0.025642  0.054181  0.046403  0.009683  0.026496   \n",
        "686  0.029312  0.047693  0.051402  0.064255  0.044641  0.000000  0.023334   \n",
        "687  0.036121  0.043517  0.054339  0.063194  0.048490  0.005249  0.025532   \n",
        "688  0.050722  0.044839  0.051790  0.056904  0.039364  0.016819  0.025348   \n",
        "689  0.054222  0.066100  0.045877  0.066135  0.036163  0.026049  0.029347   \n",
        "690  0.043935  0.095575  0.048626  0.062397  0.029433  0.027465  0.010720   \n",
        "691  0.044670  0.090199  0.059187  0.049636  0.022346  0.029477  0.000000   \n",
        "692  0.042678  0.066789  0.046648  0.031474  0.032154  0.030738  0.006457   \n",
        "693  0.030165  0.042092  0.027145  0.018202  0.038294  0.014924  0.010354   \n",
        "694  0.030523  0.035805  0.019054  0.018969  0.037530  0.006404  0.020029   \n",
        "695  0.030675  0.037350  0.016521  0.019691  0.046888  0.006561  0.013509   \n",
        "696  0.015213  0.035534  0.013704  0.021559  0.052132  0.006087  0.016061   \n",
        "697  0.009294  0.029404  0.010319  0.026816  0.036316  0.005322  0.015921   \n",
        "698  0.016460  0.023177  0.008780  0.027274  0.034482  0.012093  0.006264   \n",
        "699  0.020561  0.017215  0.017295  0.021323  0.044168  0.010262  0.008538   \n",
        "700  0.027824  0.009726  0.026813  0.030858  0.057100  0.004963  0.008244   \n",
        "701  0.034411  0.013310  0.029844  0.032418  0.056895  0.009425  0.007286   \n",
        "702  0.043856  0.030607  0.029160  0.029438  0.046099  0.012303  0.020760   \n",
        "703  0.053614  0.034781  0.024181  0.031273  0.048368  0.020015  0.028729   \n",
        "704  0.053173  0.042496  0.041244  0.041071  0.059329  0.039795  0.031753   \n",
        "705  0.050943  0.060420  0.052791  0.055973  0.052274  0.042389  0.035578   \n",
        "706  0.072069  0.072675  0.052823  0.071421  0.050409  0.042590  0.045525   \n",
        "707  0.077163  0.069848  0.062215  0.082706  0.056369  0.043347  0.049044   \n",
        "708  0.081982  0.069438  0.078841  0.086611  0.079127  0.043915  0.074054   \n",
        "709  0.094514  0.073215  0.089470  0.092221  0.090868  0.060300  0.088312   \n",
        "710  0.107791  0.100121  0.113278  0.108582  0.115651  0.086994  0.101025   \n",
        "711  0.138536  0.143042  0.149614  0.143593  0.146349  0.115075  0.127445   \n",
        "712  0.176436  0.185135  0.206127  0.201152  0.175077  0.150211  0.157050   \n",
        "713  0.210867  0.237449  0.256136  0.271831  0.216952  0.203890  0.202297   \n",
        "714  0.267861  0.297873  0.323736  0.331764  0.290727  0.279051  0.278205   \n",
        "715  0.375097  0.389569  0.436135  0.429389  0.419035  0.394232  0.385442   \n",
        "716  0.530477  0.520903  0.593893  0.569667  0.578608  0.520847  0.545637   \n",
        "717  0.723902  0.709542  0.777529  0.770316  0.778163  0.698289  0.750038   \n",
        "718  0.892645  0.890009  0.921096  0.921805  0.923914  0.891495  0.906542   \n",
        "719  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
        "\n",
        "     spectra8  spectra9  spectra10    ...      spectra16  spectra17  \\\n",
        "672  0.028776  0.020530   0.051182    ...       0.016331   0.056767   \n",
        "673  0.025444  0.020530   0.046596    ...       0.016331   0.048259   \n",
        "674  0.031771  0.029710   0.029165    ...       0.021160   0.053163   \n",
        "675  0.031411  0.024778   0.011001    ...       0.017167   0.043780   \n",
        "676  0.019035  0.013963   0.005028    ...       0.001109   0.026387   \n",
        "677  0.018570  0.017503   0.015733    ...       0.008979   0.035515   \n",
        "678  0.023101  0.006296   0.011117    ...       0.020100   0.034827   \n",
        "679  0.012339  0.000000   0.000000    ...       0.028280   0.025953   \n",
        "680  0.000641  0.013201   0.005104    ...       0.017412   0.017833   \n",
        "681  0.000000  0.008616   0.018650    ...       0.006659   0.010570   \n",
        "682  0.013676  0.004357   0.014718    ...       0.005296   0.009402   \n",
        "683  0.022601  0.021732   0.012845    ...       0.001802   0.014316   \n",
        "684  0.026169  0.031574   0.025397    ...       0.000000   0.029773   \n",
        "685  0.031467  0.027935   0.035053    ...       0.010538   0.019027   \n",
        "686  0.035049  0.023412   0.035420    ...       0.019230   0.015514   \n",
        "687  0.035454  0.030541   0.034787    ...       0.028699   0.029603   \n",
        "688  0.031553  0.044170   0.032273    ...       0.043947   0.048417   \n",
        "689  0.043293  0.044445   0.027179    ...       0.043938   0.057789   \n",
        "690  0.050648  0.035167   0.030155    ...       0.032601   0.054757   \n",
        "691  0.058595  0.034005   0.028783    ...       0.024702   0.028824   \n",
        "692  0.055001  0.044087   0.028802    ...       0.027106   0.000000   \n",
        "693  0.040773  0.036527   0.020127    ...       0.030615   0.003223   \n",
        "694  0.024884  0.021907   0.008233    ...       0.012424   0.023411   \n",
        "695  0.020898  0.019541   0.012476    ...       0.011202   0.034810   \n",
        "696  0.021661  0.032291   0.016703    ...       0.012365   0.041134   \n",
        "697  0.021048  0.030038   0.029577    ...       0.017055   0.031117   \n",
        "698  0.027016  0.019022   0.037230    ...       0.029905   0.022777   \n",
        "699  0.027450  0.029516   0.027304    ...       0.028497   0.022550   \n",
        "700  0.019720  0.030583   0.019016    ...       0.028988   0.018673   \n",
        "701  0.017802  0.032804   0.030611    ...       0.025056   0.035481   \n",
        "702  0.016219  0.035723   0.038211    ...       0.015627   0.053353   \n",
        "703  0.020474  0.031408   0.048833    ...       0.017146   0.047307   \n",
        "704  0.028250  0.044165   0.071494    ...       0.030459   0.071060   \n",
        "705  0.037465  0.046649   0.082897    ...       0.024858   0.075074   \n",
        "706  0.044689  0.058132   0.077872    ...       0.030323   0.058792   \n",
        "707  0.040764  0.059685   0.065055    ...       0.050061   0.056718   \n",
        "708  0.044876  0.070054   0.074366    ...       0.058827   0.069892   \n",
        "709  0.052152  0.088212   0.086267    ...       0.073426   0.082583   \n",
        "710  0.065347  0.112814   0.105283    ...       0.103964   0.100447   \n",
        "711  0.101149  0.134100   0.136338    ...       0.138100   0.135503   \n",
        "712  0.140341  0.149804   0.160035    ...       0.165707   0.186528   \n",
        "713  0.183816  0.194049   0.191060    ...       0.206971   0.237295   \n",
        "714  0.236931  0.267634   0.271136    ...       0.262264   0.300364   \n",
        "715  0.319149  0.353547   0.387385    ...       0.357385   0.391620   \n",
        "716  0.456520  0.487118   0.516781    ...       0.513193   0.520978   \n",
        "717  0.653043  0.689657   0.684997    ...       0.709797   0.683749   \n",
        "718  0.870164  0.877555   0.869252    ...       0.903380   0.864588   \n",
        "719  1.000000  1.000000   1.000000    ...       1.000000   1.000000   \n",
        "\n",
        "     spectra18  spectra19  spectra20  spectra21  spectra22  spectra23  \\\n",
        "672   0.059561   0.017317   0.049428   0.051479   0.039777   0.032679   \n",
        "673   0.045083   0.005945   0.031930   0.051479   0.039777   0.032679   \n",
        "674   0.037622   0.007885   0.030210   0.067232   0.038306   0.023992   \n",
        "675   0.026813   0.015140   0.028529   0.057954   0.034715   0.008884   \n",
        "676   0.028496   0.019721   0.029691   0.029528   0.031927   0.008955   \n",
        "677   0.031567   0.029363   0.031893   0.012711   0.032258   0.013371   \n",
        "678   0.021374   0.025503   0.030501   0.000809   0.011124   0.015955   \n",
        "679   0.015376   0.017229   0.037705   0.000000   0.002174   0.011832   \n",
        "680   0.011430   0.007938   0.028417   0.007232   0.000000   0.003676   \n",
        "681   0.000000   0.003503   0.015920   0.013317   0.003774   0.006838   \n",
        "682   0.004887   0.002060   0.013676   0.017262   0.019083   0.023764   \n",
        "683   0.025680   0.000000   0.026892   0.009361   0.022409   0.036504   \n",
        "684   0.029969   0.010051   0.042146   0.009884   0.038315   0.031910   \n",
        "685   0.029682   0.017743   0.052460   0.027488   0.060952   0.018416   \n",
        "686   0.025152   0.020610   0.052727   0.037284   0.066906   0.009940   \n",
        "687   0.033139   0.027176   0.040567   0.052778   0.059721   0.027869   \n",
        "688   0.040031   0.046387   0.026818   0.062390   0.048813   0.043412   \n",
        "689   0.053331   0.045274   0.039365   0.043874   0.040361   0.042484   \n",
        "690   0.056899   0.033517   0.046227   0.024340   0.040550   0.038985   \n",
        "691   0.055560   0.014946   0.027317   0.030857   0.031756   0.037989   \n",
        "692   0.061387   0.016890   0.018052   0.045816   0.037742   0.038735   \n",
        "693   0.066457   0.019064   0.024672   0.043705   0.041751   0.033869   \n",
        "694   0.061448   0.017831   0.015082   0.018973   0.037189   0.019196   \n",
        "695   0.054667   0.023373   0.000000   0.004889   0.034870   0.017676   \n",
        "696   0.062101   0.040823   0.004030   0.007303   0.015056   0.032052   \n",
        "697   0.068321   0.044947   0.008266   0.016372   0.008328   0.034816   \n",
        "698   0.071881   0.029277   0.020425   0.031009   0.007880   0.018684   \n",
        "699   0.078326   0.017380   0.038597   0.040408   0.009210   0.000000   \n",
        "700   0.073237   0.030332   0.050279   0.028242   0.018149   0.003259   \n",
        "701   0.069981   0.045300   0.044387   0.020432   0.025139   0.013964   \n",
        "702   0.069422   0.048023   0.036956   0.035026   0.036948   0.022434   \n",
        "703   0.066169   0.042917   0.053072   0.033601   0.037562   0.024826   \n",
        "704   0.076743   0.055389   0.077787   0.036892   0.043521   0.030098   \n",
        "705   0.086447   0.065453   0.063709   0.041639   0.044660   0.032664   \n",
        "706   0.074710   0.071633   0.047115   0.044530   0.052481   0.039362   \n",
        "707   0.073164   0.071142   0.051547   0.044897   0.063092   0.046093   \n",
        "708   0.086809   0.073532   0.063573   0.054162   0.075192   0.055702   \n",
        "709   0.089511   0.085854   0.075320   0.057579   0.083363   0.075309   \n",
        "710   0.095488   0.105069   0.097719   0.068278   0.093066   0.095278   \n",
        "711   0.111481   0.117460   0.134495   0.101466   0.115742   0.109436   \n",
        "712   0.138849   0.146000   0.177008   0.136876   0.150064   0.141683   \n",
        "713   0.175586   0.201067   0.231865   0.167677   0.188365   0.185633   \n",
        "714   0.235082   0.282160   0.289154   0.230782   0.239356   0.240059   \n",
        "715   0.339856   0.378186   0.392391   0.339553   0.330507   0.314801   \n",
        "716   0.481048   0.504511   0.539673   0.488397   0.462871   0.440870   \n",
        "717   0.663436   0.689099   0.717148   0.679078   0.678106   0.643080   \n",
        "718   0.878948   0.886192   0.879085   0.883214   0.897791   0.873885   \n",
        "719   1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
        "\n",
        "     spectra24  spectra25  \n",
        "672   0.051023   0.044873  \n",
        "673   0.034599   0.034209  \n",
        "674   0.015429   0.038883  \n",
        "675   0.016687   0.032201  \n",
        "676   0.032154   0.012346  \n",
        "677   0.046418   0.010671  \n",
        "678   0.037785   0.006831  \n",
        "679   0.021636   0.005015  \n",
        "680   0.008373   0.008504  \n",
        "681   0.020073   0.000000  \n",
        "682   0.030163   0.015951  \n",
        "683   0.027715   0.029956  \n",
        "684   0.028349   0.038308  \n",
        "685   0.028537   0.056217  \n",
        "686   0.037993   0.066328  \n",
        "687   0.045149   0.062281  \n",
        "688   0.047568   0.060425  \n",
        "689   0.057504   0.064650  \n",
        "690   0.059328   0.073344  \n",
        "691   0.046759   0.085942  \n",
        "692   0.040076   0.073989  \n",
        "693   0.036140   0.064670  \n",
        "694   0.034919   0.060791  \n",
        "695   0.030324   0.055753  \n",
        "696   0.026719   0.064800  \n",
        "697   0.030959   0.061212  \n",
        "698   0.035724   0.044501  \n",
        "699   0.032511   0.037674  \n",
        "700   0.021431   0.032603  \n",
        "701   0.003038   0.025448  \n",
        "702   0.000000   0.033601  \n",
        "703   0.011513   0.030191  \n",
        "704   0.035352   0.032496  \n",
        "705   0.045543   0.037055  \n",
        "706   0.048557   0.035329  \n",
        "707   0.046245   0.037006  \n",
        "708   0.051065   0.047969  \n",
        "709   0.065243   0.053278  \n",
        "710   0.084113   0.073279  \n",
        "711   0.094553   0.103927  \n",
        "712   0.114005   0.131441  \n",
        "713   0.152328   0.176600  \n",
        "714   0.217934   0.235999  \n",
        "715   0.317851   0.334975  \n",
        "716   0.450708   0.479189  \n",
        "717   0.660923   0.676654  \n",
        "718   0.876304   0.867436  \n",
        "719   1.000000   1.000000  \n",
        "\n",
        "[48 rows x 25 columns]"
       ]
      }
     ],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Hunt on traitors\n",
      "\n",
      "df_len1 = len(df)\n",
      "df_len2 = len(df[0].iloc[0])\n",
      "#print(df_len1)\n",
      "x_arr = np.empty([df_len1, df_len2], dtype = float)\n",
      "\n",
      "for i in df_len:\n",
      "    if len(x_arr[i]) == len(x_norm[i]):\n",
      "        x_arr[i] = x_norm[i]\n",
      "    elif len(x_arr[i]) > len(x_norm[i]):\n",
      "        k=0\n",
      "        while k < len(x_norm[i]):\n",
      "            x_arr[i][k] = x_norm[i][k]\n",
      "            k = k+1\n",
      "            \n",
      "    #print(x_arr[i])\n",
      "    #print(x[i])\n",
      "\n",
      "pvalue = 0\n",
      "\n",
      "traitor = 404\n",
      "\n",
      "if Alert:\n",
      "    if df_len1 == 4:\n",
      "        pvalue = scipy.stats.kruskal(x_arr[0], x_arr[1], x_arr[2], x_arr[3])[1]\n",
      "    elif df_len1 == 5: \n",
      "        pvalue = scipy.stats.kruskal(x_arr[0], x_arr[1], x_arr[2], x_arr[3], x_arr[4])[1]\n",
      "    elif df_len1 == 6:\n",
      "        pvalue = scipy.stats.kruskal(x_arr[0], x_arr[1], x_arr[2], x_arr[3], x_arr[4], x_arr[5])[1]\n",
      "    elif df_len1 == 7:\n",
      "        pvalue = scipy.stats.kruskal(x_arr[0], x_arr[1], x_arr[2], x_arr[3], x_arr[4], x_arr[5], x_arr[6])[1]\n",
      "    else:\n",
      "        print('PANIC!!!')\n",
      "    \n",
      "    if pvalue <= 0.05:\n",
      "        for i in xrange(df_len1):\n",
      "            for j in xrange(df_len1-1):\n",
      "                #print(i, j, scipy.stats.ttest_ind(x_arr[i], x_arr[j])[1])\n",
      "                if scipy.stats.mannwhitneyu(x_arr[i], x_arr[j])[1] < 0.05 and scipy.stats.mannwhitneyu(x_arr[i], x_arr[j+1])[1] < 0.05 :\n",
      "                    traitor = i\n",
      "                    break\n",
      "    else:\n",
      "        pvalue = 0\n",
      "\n",
      "                    \n",
      "#pvalue = 0\n",
      "else:\n",
      "    if df_len1 == 4:\n",
      "        pvalue = scipy.stats.f_oneway(x_arr[0], x_arr[1], x_arr[2], x_arr[3])[1]\n",
      "    elif df_len1 == 5: \n",
      "        pvalue = scipy.stats.f_oneway(x_arr[0], x_arr[1], x_arr[2], x_arr[3], x_arr[4])[1]\n",
      "    elif df_len1 == 6:\n",
      "        pvalue = scipy.stats.f_oneway(x_arr[0], x_arr[1], x_arr[2], x_arr[3], x_arr[4], x_arr[5])[1]\n",
      "    elif df_len1 == 7:\n",
      "        pvalue = scipy.stats.f_oneway(x_arr[0], x_arr[1], x_arr[2], x_arr[3], x_arr[4], x_arr[5], x_arr[6])[1]\n",
      "    else:\n",
      "        print('PANIC!!!')\n",
      "    \n",
      "    if pvalue <= 0.05:\n",
      "        for i in xrange(df_len1):\n",
      "            for j in xrange(df_len1-1):\n",
      "                #print(i, j, scipy.stats.ttest_ind(x_arr[i], x_arr[j])[1])\n",
      "                if scipy.stats.ttest_ind(x_arr[i], x_arr[j])[1] < 0.05 and scipy.stats.ttest_ind(x_arr[i], x_arr[j+1])[1] < 0.05 :\n",
      "                    traitor = i\n",
      "                    break\n",
      "\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PANIC!!!\n"
       ]
      }
     ],
     "prompt_number": 234
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_nonorm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 235,
       "text": [
        "[array([ 468972.73661538]), array([ 581041.10707692])]"
       ]
      }
     ],
     "prompt_number": 235
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_len1 = len(df_mean_no_normal)\n",
      "df_len2 = len(df_mean_no_normal[0].iloc[0])\n",
      "#print(df_len1)\n",
      "x_arr_1 = np.empty([df_len1, df_len2], dtype = float)\n",
      "\n",
      "for i in df_len:\n",
      "    if len(x_arr_1[i]) == len(x_nonorm[i]):\n",
      "        x_arr_1[i] = x_nonorm[i]\n",
      "    elif len(x_arr_1[i]) > len(x_nonorm[i]):\n",
      "        k=0\n",
      "        while k < len(x_nonorm[i]):\n",
      "            x_arr_1[i][k] = x_nonorm[i][k]\n",
      "            k = k+1\n",
      "            \n",
      "    #print(x_arr_1[i])\n",
      "    #print(x[i])\n",
      "\n",
      "pvalue = 0\n",
      "\n",
      "traitor = 404\n",
      "\n",
      "if Alert:\n",
      "    if df_len1 == 4:\n",
      "        pvalue = scipy.stats.kruskal(x_arr_1[0], x_arr_1[1], x_arr_1[2], x_arr_1[3])[1]\n",
      "    elif df_len1 == 5: \n",
      "        pvalue = scipy.stats.kruskal(x_arr_1[0], x_arr_1[1], x_arr_1[2], x_arr_1[3], x_arr_1[4])[1]\n",
      "    elif df_len1 == 6:\n",
      "        pvalue = scipy.stats.kruskal(x_arr_1[0], x_arr_1[1], x_arr_1[2], x_arr_1[3], x_arr_1[4], x_arr_1[5])[1]\n",
      "    elif df_len1 == 7:\n",
      "        pvalue = scipy.stats.kruskal(x_arr_1[0], x_arr_1[1], x_arr_1[2], x_arr_1[3], x_arr_1[4], x_arr_1[5], x_arr_1[6])[1]\n",
      "    else:\n",
      "        print('PANIC!!!')\n",
      "    \n",
      "    if pvalue <= 0.05:\n",
      "        for i in xrange(df_len1):\n",
      "            for j in xrange(df_len1-1):\n",
      "                #print(i, j, scipy.stats.ttest_ind(x_arr_1[i], x_arr_1[j])[1])\n",
      "                if scipy.stats.mannwhitneyu(x_arr_1[i], x_arr_1[j])[1] < 0.05 and scipy.stats.mannwhitneyu(x_arr_1[i], x_arr_1[j+1])[1] < 0.05 :\n",
      "                    traitor = i\n",
      "                    break\n",
      "    else:\n",
      "        pvalue = 0\n",
      "\n",
      "                    \n",
      "#pvalue = 0\n",
      "else:\n",
      "    if df_len1 == 2:\n",
      "        pvalue = scipy.stats.f_oneway(x_arr_1[0], x_arr_1[1])[1]\n",
      "    if df_len1 == 4:\n",
      "        pvalue = scipy.stats.f_oneway(x_arr_1[0], x_arr_1[1], x_arr_1[2], x_arr_1[3])[1]\n",
      "    elif df_len1 == 5: \n",
      "        pvalue = scipy.stats.f_oneway(x_arr_1[0], x_arr_1[1], x_arr_1[2], x_arr_1[3], x_arr_1[4])[1]\n",
      "    elif df_len1 == 6:\n",
      "        pvalue = scipy.stats.f_oneway(x_arr_1[0], x_arr_1[1], x_arr_1[2], x_arr_1[3], x_arr_1[4], x_arr_1[5])[1]\n",
      "    elif df_len1 == 7:\n",
      "        pvalue = scipy.stats.f_oneway(x_arr_1[0], x_arr_1[1], x_arr_1[2], x_arr_1[3], x_arr_1[4], x_arr_1[5], x_arr_1[6])[1]\n",
      "    else:\n",
      "        print('PANIC!!!')\n",
      "    \n",
      "    if pvalue <= 0.05:\n",
      "        for i in xrange(df_len1):\n",
      "            for j in xrange(df_len1-1):\n",
      "                #print(i, j, scipy.stats.ttest_ind(x_arr_1[i], x_arr_1[j])[1])\n",
      "                if scipy.stats.ttest_ind(x_arr_1[i], x_arr_1[j])[1] < 0.05 and scipy.stats.ttest_ind(x_arr_1[i], x_arr_1[j+1])[1] < 0.05 :\n",
      "                    traitor = i\n",
      "                    break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PANIC!!!\n"
       ]
      }
     ],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#new values\n",
      "\n",
      "mean_new = []\n",
      "\n",
      "for i in df_len:\n",
      "    if i != traitor:\n",
      "        print(x_norm[i])\n",
      "        mean_new.append(np.mean(x_norm[i]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.03721704  0.04262776  0.04285494  0.02527209  0.03555313  0.03252338\n",
        "  0.04391368  0.0287759   0.02053     0.05118228  0.03166578  0.03685503\n",
        "  0.03599245  0.05747862  0.02207023  0.01633141  0.05676686  0.05956076\n",
        "  0.01731695  0.04942787  0.05147944  0.03977667  0.03267859  0.05102259\n",
        "  0.04487315]\n",
        "[ 0.02643237  0.02258807  0.00702072  0.03941868  0.02391036  0.02502452\n",
        "  0.03477549  0.03033324  0.01962592  0.04030059  0.02619603  0.04611634\n",
        "  0.03564265  0.02919026  0.06402707  0.02635787  0.02212069  0.01854986\n",
        "  0.06062965  0.04796551  0.05405144  0.03546584  0.02803699  0.05297267\n",
        "  0.03880396]\n"
       ]
      }
     ],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#new values\n",
      "\n",
      "mean_new_1 = []\n",
      "\n",
      "for i in df_len:\n",
      "    if i != traitor:\n",
      "        print(x_nonorm[i])\n",
      "        mean_new_1.append(np.mean(x_nonorm[i]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 468972.73661538]\n",
        "[ 581041.10707692]\n"
       ]
      }
     ],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_new "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 239,
       "text": [
        "[0.03854986396066331, 0.034222271041780092]"
       ]
      }
     ],
     "prompt_number": 239
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in df_len:\n",
      "    mean_new[i] = mean_new[i]*mean_new_1[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 240
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_new"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 241,
       "text": [
        "[18078.835197783064, 19884.546252802429]"
       ]
      }
     ],
     "prompt_number": 241
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#statistics\n",
      "\n",
      "ValueOfAg = np.mean(mean_new)\n",
      "StdOfAg = np.std(mean_new)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open(path_konets + \"/\" + \"res.out\", \"a\")\n",
      "f.write(path + \"/\" + name + \",\" + str(ValueOfAg) + \",\" + str(StdOfAg) + \",\" + \"\\n\")\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 243
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "(time[0]+80)/100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 244,
       "text": [
        "5"
       ]
      }
     ],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 244
    }
   ],
   "metadata": {}
  }
 ]
}